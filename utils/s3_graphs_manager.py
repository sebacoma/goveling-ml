#!/usr/bin/env python3
"""
ğŸ“¦ AMAZON S3 GRAPHS MANAGER FOR CHILE
Gestor profesional de grafos usando Amazon S3 (escalable, seguro, rÃ¡pido)
"""

import os
import pickle
import gzip
import logging
import boto3
from botocore.exceptions import NoCredentialsError, ClientError
from typing import Dict, Optional, List
import json
import tempfile
from pathlib import Path

logger = logging.getLogger(__name__)

class S3GraphsManager:
    """
    Gestor profesional para subir/descargar grafos de Chile usando Amazon S3
    
    Ventajas vs Google Drive:
    - âœ… MÃ¡s rÃ¡pido (CDN global)  
    - âœ… MÃ¡s confiable (99.999999999% durabilidad)
    - âœ… Mejor integraciÃ³n con aplicaciones
    - âœ… Versionado automÃ¡tico
    - âœ… Escalabilidad profesional
    """
    
    def __init__(self, config_file: str = "s3_config.json"):
        """
        Inicializar el manager de S3
        
        Args:
            config_file (str): Archivo JSON con configuraciÃ³n S3
        """
        self.cache_dir = "cache"
        self.config_file = config_file
        
        # Crear directorio cache si no existe
        os.makedirs(self.cache_dir, exist_ok=True)
        
        # Cargar configuraciÃ³n
        self.config = self._load_config()
        
        # Inicializar cliente S3
        self.s3_client = None
        self._init_s3_client()
        
        logger.info(f"S3GraphsManager inicializado con {len(self.config.get('files', {}))} archivos")
    
    def _load_config(self) -> Dict:
        """Cargar configuraciÃ³n desde archivo JSON"""
        try:
            if not os.path.exists(self.config_file):
                logger.warning(f"No existe {self.config_file}, usando configuraciÃ³n vacÃ­a")
                return {}
            
            with open(self.config_file, 'r') as f:
                config = json.load(f)
            
            # Validar estructura requerida
            required_keys = ['bucket_name', 'region', 'files']
            for key in required_keys:
                if key not in config:
                    logger.error(f"ConfiguraciÃ³n S3 invÃ¡lida: falta '{key}'")
                    return {}
            
            logger.info(f"ConfiguraciÃ³n S3 cargada: bucket={config['bucket_name']}, region={config['region']}")
            return config
            
        except Exception as e:
            logger.error(f"Error cargando configuraciÃ³n S3: {e}")
            return {}
    
    def _init_s3_client(self):
        """Inicializar cliente de S3 con credenciales"""
        if not self.config:
            return
        
        try:
            # MÃ©todo 1: Credenciales desde archivo de configuraciÃ³n
            if 'aws_access_key_id' in self.config and 'aws_secret_access_key' in self.config:
                self.s3_client = boto3.client(
                    's3',
                    aws_access_key_id=self.config['aws_access_key_id'],
                    aws_secret_access_key=self.config['aws_secret_access_key'],
                    region_name=self.config['region']
                )
                logger.info("âœ… Cliente S3 inicializado con credenciales del archivo config")
            
            # MÃ©todo 2: Credenciales desde variables de entorno
            elif os.getenv('AWS_ACCESS_KEY_ID') and os.getenv('AWS_SECRET_ACCESS_KEY'):
                self.s3_client = boto3.client(
                    's3',
                    region_name=self.config['region']
                )
                logger.info("âœ… Cliente S3 inicializado con variables de entorno")
            
            # MÃ©todo 3: IAM Role (recomendado para producciÃ³n)
            else:
                self.s3_client = boto3.client(
                    's3',
                    region_name=self.config['region']
                )
                logger.info("âœ… Cliente S3 inicializado con IAM Role")
                
        except Exception as e:
            logger.error(f"âŒ Error inicializando cliente S3: {e}")
            self.s3_client = None
    
    def _get_s3_key(self, filename: str) -> str:
        """
        Obtener la clave S3 para un archivo
        
        Args:
            filename (str): Nombre del archivo local
            
        Returns:
            str: Clave S3 (path en el bucket)
        """
        # Usar prefijo para organizar archivos
        prefix = self.config.get('prefix', 'goveling-ml/graphs')
        return f"{prefix}/{filename}.gz"
    
    def download_graph(self, filename: str, force_redownload: bool = False) -> bool:
        """
        Descargar un grafo especÃ­fico desde S3
        
        Args:
            filename (str): Nombre del archivo a descargar (ej: 'chile_graph_cache.pkl')
            force_redownload (bool): Forzar re-descarga si el archivo ya existe
        
        Returns:
            bool: True si se descargÃ³ exitosamente
        """
        if not self.s3_client:
            logger.error("âŒ Cliente S3 no inicializado")
            return False
        
        local_path = os.path.join(self.cache_dir, filename)
        
        # Verificar si ya existe y no forzar re-descarga
        if os.path.exists(local_path) and not force_redownload:
            logger.info(f"âœ… {filename} ya existe localmente")
            return True
        
        try:
            bucket_name = self.config['bucket_name']
            s3_key = self._get_s3_key(filename)
            
            logger.info(f"â¬‡ï¸ Descargando {filename} desde S3: s3://{bucket_name}/{s3_key}")
            
            # Descargar archivo comprimido a temporal
            compressed_path = local_path + '.gz'
            
            # Verificar que el objeto existe en S3
            try:
                self.s3_client.head_object(Bucket=bucket_name, Key=s3_key)
            except ClientError as e:
                if e.response['Error']['Code'] == '404':
                    logger.error(f"âŒ Archivo no encontrado en S3: {s3_key}")
                    return False
                raise
            
            # Descargar archivo
            self.s3_client.download_file(bucket_name, s3_key, compressed_path)
            
            # Descomprimir archivo
            logger.info(f"ğŸ“¦ Descomprimiendo {filename}...")
            with gzip.open(compressed_path, 'rb') as f_gz:
                with open(local_path, 'wb') as f_out:
                    f_out.write(f_gz.read())
            
            # Obtener tamaÃ±os para logging
            compressed_size = os.path.getsize(compressed_path)
            uncompressed_size = os.path.getsize(local_path)
            
            logger.info(f"âœ… {filename} descargado exitosamente")
            logger.info(f"   ğŸ“Š TamaÃ±o: {compressed_size/1024/1024:.1f}MB â†’ {uncompressed_size/1024/1024:.1f}MB")
            
            # Limpiar archivo comprimido temporal (opcional)
            # os.remove(compressed_path)
            
            return True
            
        except NoCredentialsError:
            logger.error("âŒ Credenciales AWS no encontradas")
            return False
        except ClientError as e:
            logger.error(f"âŒ Error S3: {e}")
            return False
        except Exception as e:
            logger.error(f"âŒ Error descargando {filename}: {e}")
            
            # Limpiar archivos parciales
            for path in [local_path, local_path + '.gz']:
                if os.path.exists(path):
                    try:
                        os.remove(path)
                    except:
                        pass
            
            return False
    
    def upload_graph(self, filename: str, compress: bool = True) -> bool:
        """
        Subir un grafo local a S3
        
        Args:
            filename (str): Nombre del archivo a subir
            compress (bool): Comprimir antes de subir
            
        Returns:
            bool: True si se subiÃ³ exitosamente
        """
        if not self.s3_client:
            logger.error("âŒ Cliente S3 no inicializado")
            return False
        
        local_path = os.path.join(self.cache_dir, filename)
        
        if not os.path.exists(local_path):
            logger.error(f"âŒ Archivo local no existe: {local_path}")
            return False
        
        try:
            bucket_name = self.config['bucket_name']
            s3_key = self._get_s3_key(filename)
            
            if compress:
                # Comprimir antes de subir
                compressed_path = local_path + '.gz'
                if not os.path.exists(compressed_path):
                    logger.info(f"ğŸ—œï¸ Comprimiendo {filename}...")
                    with open(local_path, 'rb') as f_in:
                        with gzip.open(compressed_path, 'wb') as f_out:
                            f_out.write(f_in.read())
                
                upload_path = compressed_path
                original_size = os.path.getsize(local_path)
                compressed_size = os.path.getsize(compressed_path)
                compression_ratio = (1 - compressed_size/original_size) * 100
                
                logger.info(f"ğŸ“¦ CompresiÃ³n: {original_size/1024/1024:.1f}MB â†’ {compressed_size/1024/1024:.1f}MB ({compression_ratio:.1f}% reducciÃ³n)")
            else:
                upload_path = local_path
            
            # Subir a S3
            logger.info(f"â¬†ï¸ Subiendo a S3: s3://{bucket_name}/{s3_key}")
            
            # Subir con metadata
            extra_args = {
                'Metadata': {
                    'original-filename': filename,
                    'upload-timestamp': str(int(os.path.getmtime(local_path))),
                    'goveling-version': '1.0'
                }
            }
            
            self.s3_client.upload_file(upload_path, bucket_name, s3_key, ExtraArgs=extra_args)
            
            logger.info(f"âœ… {filename} subido exitosamente a S3")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error subiendo {filename}: {e}")
            return False
    
    def check_cache_status(self) -> Dict:
        """
        Verifica el estado de todos los archivos de cachÃ© (local y S3)
        
        Returns:
            dict: Estado de cada archivo
        """
        status = {}
        
        if not self.config.get('files'):
            return status
        
        for filename in self.config['files'].keys():
            local_path = os.path.join(self.cache_dir, filename)
            compressed_path = local_path + '.gz'
            
            file_info = {
                'exists_local': os.path.exists(local_path),
                'exists_compressed': os.path.exists(compressed_path),
                'exists_s3': False,
                'size_local': None,
                'size_compressed': None,
                'size_s3': None
            }
            
            # InformaciÃ³n local
            if file_info['exists_local']:
                file_info['size_local'] = os.path.getsize(local_path)
            
            if file_info['exists_compressed']:
                file_info['size_compressed'] = os.path.getsize(compressed_path)
            
            # InformaciÃ³n S3
            if self.s3_client:
                try:
                    s3_key = self._get_s3_key(filename)
                    response = self.s3_client.head_object(
                        Bucket=self.config['bucket_name'], 
                        Key=s3_key
                    )
                    file_info['exists_s3'] = True
                    file_info['size_s3'] = response['ContentLength']
                except ClientError:
                    file_info['exists_s3'] = False
            
            status[filename] = file_info
        
        return status
    
    def download_all_graphs(self, force_redownload: bool = False) -> Dict:
        """
        Descarga todos los grafos desde S3 si no existen localmente
        
        Args:
            force_redownload (bool): Forzar re-descarga incluso si los archivos existen
        
        Returns:
            dict: Estado de descarga para cada archivo
        """
        if not self.config.get('files'):
            logger.error("No hay archivos configurados en S3")
            return {}
        
        download_status = {}
        
        for filename in self.config['files'].keys():
            try:
                success = self.download_graph(filename, force_redownload)
                download_status[filename] = success
                
                if success:
                    logger.info(f"âœ… {filename} descargado y listo")
                else:
                    logger.warning(f"âš ï¸ {filename} no se pudo descargar")
                    
            except Exception as e:
                logger.error(f"âŒ Error descargando {filename}: {e}")
                download_status[filename] = False
        
        # Resumen
        successful = sum(1 for status in download_status.values() if status)
        total = len(download_status)
        
        logger.info(f"ğŸ“Š Descarga desde S3 completada: {successful}/{total} archivos")
        
        return download_status
    
    def ensure_critical_graphs(self) -> bool:
        """
        Asegurar que los grafos crÃ­ticos estÃ©n disponibles
        
        Returns:
            bool: True si todos los grafos crÃ­ticos estÃ¡n disponibles
        """
        if not self.config.get('files'):
            logger.warning("No hay archivos definidos en configuraciÃ³n S3")
            return True
        
        critical_files = [
            filename for filename, info in self.config['files'].items()
            if info.get('priority') == 'critical'
        ]
        
        if not critical_files:
            logger.warning("No hay archivos crÃ­ticos definidos")
            return True
        
        missing_files = []
        for filename in critical_files:
            local_path = os.path.join(self.cache_dir, filename)
            if not os.path.exists(local_path):
                missing_files.append(filename)
        
        if not missing_files:
            logger.info("âœ… Todos los grafos crÃ­ticos estÃ¡n disponibles")
            return True
        
        logger.info(f"â¬‡ï¸ Descargando {len(missing_files)} grafos crÃ­ticos desde S3...")
        
        # Descargar archivos crÃ­ticos faltantes
        download_status = {}
        for filename in missing_files:
            success = self.download_graph(filename)
            download_status[filename] = success
        
        # Verificar si todos se descargaron exitosamente
        all_downloaded = all(download_status.values())
        
        if all_downloaded:
            logger.info("âœ… Todos los grafos crÃ­ticos descargados desde S3")
        else:
            failed = [f for f, success in download_status.items() if not success]
            logger.error(f"âŒ FallÃ³ descarga de grafos crÃ­ticos desde S3: {failed}")
        
        return all_downloaded


# FunciÃ³n de conveniencia
def get_s3_graphs_manager() -> S3GraphsManager:
    """
    Obtener instancia del manager S3 configurado
    
    Returns:
        S3GraphsManager: Manager listo para usar
    """
    return S3GraphsManager()


# CLI para gestiÃ³n S3
if __name__ == "__main__":
    """
    Interfaz de lÃ­nea de comandos para gestionar grafos en S3
    """
    import sys
    
    print("ğŸš€ AMAZON S3 GRAPHS MANAGER")
    print("=" * 50)
    
    manager = S3GraphsManager()
    
    if not manager.config:
        print("âŒ No hay configuraciÃ³n S3 disponible")
        print("ğŸ’¡ Crea: s3_config.json con bucket, regiÃ³n y credenciales")
        sys.exit(1)
    
    if not manager.s3_client:
        print("âŒ Cliente S3 no inicializado")
        print("ğŸ’¡ Verifica credenciales AWS")
        sys.exit(1)
    
    # MenÃº interactivo
    while True:
        print("\nğŸ“‹ OPCIONES S3:")
        print("1. Ver estado de archivos (local + S3)")
        print("2. Descargar todos los grafos desde S3")
        print("3. Subir todos los grafos a S3")  
        print("4. Asegurar grafos crÃ­ticos")
        print("5. Descargar archivo especÃ­fico")
        print("6. Subir archivo especÃ­fico")
        print("7. Salir")
        
        try:
            choice = input("\nğŸ¯ Elige una opciÃ³n (1-7): ").strip()
            
            if choice == "1":
                print("\nğŸ“Š ESTADO DE ARCHIVOS:")
                status = manager.check_cache_status()
                for filename, info in status.items():
                    local_icon = "âœ…" if info['exists_local'] else "âŒ"
                    s3_icon = "â˜ï¸âœ…" if info['exists_s3'] else "â˜ï¸âŒ"
                    print(f"   {local_icon} Local: {filename}")
                    print(f"   {s3_icon} S3: {filename}")
                    
                    if info['size_local']:
                        print(f"      ğŸ“ Local: {info['size_local']/1024/1024:.1f} MB")
                    if info['size_s3']:
                        print(f"      â˜ï¸ S3: {info['size_s3']/1024/1024:.1f} MB")
            
            elif choice == "2":
                print("\nâ¬‡ï¸ DESCARGANDO TODOS LOS GRAFOS DESDE S3...")
                results = manager.download_all_graphs()
                
                print("\nğŸ“Š RESULTADOS:")
                for filename, success in results.items():
                    icon = "âœ…" if success else "âŒ"
                    print(f"   {icon} {filename}")
            
            elif choice == "3":
                print("\nâ¬†ï¸ SUBIENDO TODOS LOS GRAFOS A S3...")
                files = list(manager.config['files'].keys())
                
                for filename in files:
                    print(f"\nğŸ“¤ Subiendo {filename}...")
                    success = manager.upload_graph(filename)
                    icon = "âœ…" if success else "âŒ"
                    print(f"   {icon} {filename}")
            
            elif choice == "4":
                print("\nğŸ¯ ASEGURANDO GRAFOS CRÃTICOS...")
                success = manager.ensure_critical_graphs()
                
                if success:
                    print("âœ… Grafos crÃ­ticos listos")
                else:
                    print("âŒ Error asegurando grafos crÃ­ticos")
            
            elif choice in ["5", "6"]:
                print("\nğŸ“ ARCHIVOS DISPONIBLES:")
                files = list(manager.config['files'].keys())
                for i, filename in enumerate(files, 1):
                    print(f"   {i}. {filename}")
                
                try:
                    file_choice = int(input("\nğŸ¯ NÃºmero de archivo: ")) - 1
                    
                    if 0 <= file_choice < len(files):
                        filename = files[file_choice]
                        
                        if choice == "5":  # Descargar
                            print(f"\nâ¬‡ï¸ Descargando {filename}...")
                            success = manager.download_graph(filename, force_redownload=True)
                        else:  # Subir
                            print(f"\nâ¬†ï¸ Subiendo {filename}...")
                            success = manager.upload_graph(filename)
                        
                        icon = "âœ…" if success else "âŒ"
                        action = "descargado" if choice == "5" else "subido"
                        print(f"   {icon} {filename} {action}")
                    else:
                        print("âŒ NÃºmero invÃ¡lido")
                        
                except ValueError:
                    print("âŒ Entrada invÃ¡lida")
            
            elif choice == "7":
                print("ğŸ‘‹ Â¡Hasta luego!")
                break
                
            else:
                print("âŒ OpciÃ³n invÃ¡lida")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Â¡Hasta luego!")
            break
        except Exception as e:
            print(f"\nâŒ Error: {e}")
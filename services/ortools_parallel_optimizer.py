#!/usr/bin/env python3
"""
üöÄ OR-Tools Parallel Optimization Service - Week 4 Performance Optimization
Optimiza performance mediante paralelizaci√≥n inteligente de optimizaciones OR-Tools
"""

import logging
import asyncio
import time
from typing import List, Dict, Optional, Any, Tuple, Union
from dataclasses import dataclass
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
import json
from datetime import datetime
import multiprocessing as mp

from settings import settings

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class OptimizationTask:
    """Tarea de optimizaci√≥n para procesamiento paralelo"""
    task_id: str
    places: List[Dict]
    preferences: Dict[str, Any]
    priority: int = 1  # 1=low, 2=medium, 3=high
    timeout_seconds: int = 10
    created_at: datetime = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()

@dataclass
class OptimizationResult:
    """Resultado de optimizaci√≥n paralela"""
    task_id: str
    success: bool
    result_data: Optional[Dict[str, Any]]
    error_message: Optional[str]
    execution_time_ms: float
    worker_id: str
    source: str  # 'parallel', 'sequential', 'cached'

class ORToolsParallelOptimizer:
    """
    üßÆ Optimizador paralelo OR-Tools para m√°ximo performance
    
    Features Week 4:
    - Pool de workers dedicados para OR-Tools
    - Queue con prioridades para tareas
    - Load balancing autom√°tico
    - Circuit breaker por worker
    - Estad√≠sticas de performance detalladas
    """
    
    def __init__(self):
        self.max_workers = min(mp.cpu_count(), settings.ORTOOLS_MAX_PARALLEL_REQUESTS)
        self.executor = None
        self.task_queue = asyncio.Queue()
        self.active_tasks = {}
        self.worker_stats = {}
        
        # Performance metrics
        self.stats = {
            "total_optimizations": 0,
            "parallel_optimizations": 0,
            "sequential_optimizations": 0,
            "avg_execution_time_ms": 0.0,
            "total_execution_time_ms": 0.0,
            "success_rate": 0.0,
            "worker_utilization": 0.0
        }
        
        # Circuit breaker por worker
        self.worker_health = {}
        
        self._initialize_workers()
        logger.info(f"üöÄ ORToolsParallelOptimizer initialized - {self.max_workers} workers")
    
    def _initialize_workers(self):
        """Inicializar pool de workers OR-Tools"""
        if settings.ORTOOLS_ENABLE_PARALLEL_OPTIMIZATION:
            try:
                # Usar ProcessPoolExecutor para CPU-intensive OR-Tools operations
                self.executor = ProcessPoolExecutor(
                    max_workers=self.max_workers,
                    initializer=self._init_worker_process
                )
                
                # Inicializar estad√≠sticas por worker
                for i in range(self.max_workers):
                    worker_id = f"worker_{i}"
                    self.worker_stats[worker_id] = {
                        "optimizations_completed": 0,
                        "avg_execution_time_ms": 0.0,
                        "success_rate": 1.0,
                        "last_optimization": None
                    }
                    self.worker_health[worker_id] = {
                        "healthy": True,
                        "failures": 0,
                        "last_failure": None
                    }
                
                logger.info(f"‚úÖ OR-Tools worker pool initialized - {self.max_workers} processes")
            
            except Exception as e:
                logger.error(f"‚ùå Failed to initialize OR-Tools workers: {e}")
                self.executor = None
        else:
            logger.info("‚ö†Ô∏è Parallel optimization disabled in settings")
    
    @staticmethod
    def _init_worker_process():
        """Inicializar proceso worker con dependencias OR-Tools"""
        try:
            # Import OR-Tools en el proceso worker
            from services.city2graph_ortools_service import City2GraphORToolsService
            import os
            
            # Configurar worker ID para logging
            worker_id = f"worker_{os.getpid()}"
            
            # Configurar logging en worker
            logging.basicConfig(
                level=logging.INFO,
                format=f'%(asctime)s - {worker_id} - %(levelname)s - %(message)s'
            )
            
            logger.info(f"üîß OR-Tools worker {worker_id} initialized")
            
        except Exception as e:
            logger.error(f"‚ùå Worker initialization failed: {e}")
            raise e
    
    async def optimize_parallel(self, optimization_requests: List[OptimizationTask]) -> List[OptimizationResult]:
        """
        Optimizar m√∫ltiples requests en paralelo
        
        Args:
            optimization_requests: Lista de tareas de optimizaci√≥n
            
        Returns:
            Lista de resultados de optimizaci√≥n
        """
        if not optimization_requests:
            return []
        
        start_time = time.time()
        
        # Decidir estrategia: paralelo vs secuencial
        use_parallel = (
            len(optimization_requests) > 1 and 
            settings.ORTOOLS_ENABLE_PARALLEL_OPTIMIZATION and
            self.executor is not None
        )
        
        if use_parallel:
            logger.info(f"üöÄ Processing {len(optimization_requests)} optimizations in parallel")
            results = await self._process_parallel(optimization_requests)
            self.stats["parallel_optimizations"] += len(optimization_requests)
        else:
            logger.info(f"‚è≠Ô∏è Processing {len(optimization_requests)} optimizations sequentially")
            results = await self._process_sequential(optimization_requests)
            self.stats["sequential_optimizations"] += len(optimization_requests)
        
        # Actualizar estad√≠sticas
        total_time = (time.time() - start_time) * 1000
        self._update_global_stats(results, total_time)
        
        logger.info(f"‚úÖ Optimization batch completed - {len(results)} results in {total_time:.1f}ms")
        return results
    
    async def _process_parallel(self, tasks: List[OptimizationTask]) -> List[OptimizationResult]:
        """Procesar tareas en paralelo usando ProcessPoolExecutor"""
        if not self.executor:
            logger.warning("‚ö†Ô∏è No executor available, falling back to sequential")
            return await self._process_sequential(tasks)
        
        # Crear futures para ejecuci√≥n paralela
        loop = asyncio.get_event_loop()
        futures = []
        
        for task in tasks:
            # Enviar tarea a worker process
            future = loop.run_in_executor(
                self.executor,
                self._execute_optimization_in_worker,
                task
            )
            futures.append((task.task_id, future))
        
        # Esperar resultados con timeout
        results = []
        for task_id, future in futures:
            try:
                # Timeout per-task
                result = await asyncio.wait_for(future, timeout=30.0)
                results.append(result)
                
            except asyncio.TimeoutError:
                logger.error(f"‚è±Ô∏è Optimization timeout for task {task_id}")
                results.append(OptimizationResult(
                    task_id=task_id,
                    success=False,
                    result_data=None,
                    error_message="Optimization timeout",
                    execution_time_ms=30000.0,
                    worker_id="timeout",
                    source="parallel"
                ))
                
            except Exception as e:
                logger.error(f"‚ùå Optimization error for task {task_id}: {e}")
                results.append(OptimizationResult(
                    task_id=task_id,
                    success=False,
                    result_data=None,
                    error_message=str(e),
                    execution_time_ms=0.0,
                    worker_id="error",
                    source="parallel"
                ))
        
        return results
    
    @staticmethod
    def _execute_optimization_in_worker(task: OptimizationTask) -> OptimizationResult:
        """
        Ejecutar optimizaci√≥n OR-Tools en proceso worker
        Esta funci√≥n se ejecuta en el proceso worker
        """
        worker_id = f"worker_{mp.current_process().pid}"
        start_time = time.time()
        
        try:
            # Import OR-Tools service en worker
            from services.city2graph_ortools_service import City2GraphORToolsService
            
            # Inicializar servicio OR-Tools
            ortools_service = City2GraphORToolsService()
            
            # Ejecutar optimizaci√≥n
            result_data = ortools_service.optimize_itinerary_sync(
                places=task.places,
                preferences=task.preferences
            )
            
            execution_time = (time.time() - start_time) * 1000
            
            return OptimizationResult(
                task_id=task.task_id,
                success=True,
                result_data=result_data,
                error_message=None,
                execution_time_ms=execution_time,
                worker_id=worker_id,
                source="parallel"
            )
            
        except Exception as e:
            execution_time = (time.time() - start_time) * 1000
            
            return OptimizationResult(
                task_id=task.task_id,
                success=False,
                result_data=None,
                error_message=str(e),
                execution_time_ms=execution_time,
                worker_id=worker_id,
                source="parallel"
            )
    
    async def _process_sequential(self, tasks: List[OptimizationTask]) -> List[OptimizationResult]:
        """Procesar tareas secuencialmente como fallback"""
        results = []
        
        # Import OR-Tools service
        try:
            from services.city2graph_ortools_service import City2GraphORToolsService
            ortools_service = City2GraphORToolsService()
        except Exception as e:
            logger.error(f"‚ùå Cannot initialize OR-Tools service: {e}")
            # Return error results for all tasks
            for task in tasks:
                results.append(OptimizationResult(
                    task_id=task.task_id,
                    success=False,
                    result_data=None,
                    error_message=f"OR-Tools service initialization failed: {e}",
                    execution_time_ms=0.0,
                    worker_id="main_thread",
                    source="sequential"
                ))
            return results
        
        # Procesar cada tarea secuencialmente
        for task in tasks:
            start_time = time.time()
            
            try:
                # Ejecutar optimizaci√≥n
                result_data = await ortools_service.optimize_itinerary_async(
                    places=task.places,
                    preferences=task.preferences
                )
                
                execution_time = (time.time() - start_time) * 1000
                
                results.append(OptimizationResult(
                    task_id=task.task_id,
                    success=True,
                    result_data=result_data,
                    error_message=None,
                    execution_time_ms=execution_time,
                    worker_id="main_thread",
                    source="sequential"
                ))
                
            except Exception as e:
                execution_time = (time.time() - start_time) * 1000
                
                results.append(OptimizationResult(
                    task_id=task.task_id,
                    success=False,
                    result_data=None,
                    error_message=str(e),
                    execution_time_ms=execution_time,
                    worker_id="main_thread",
                    source="sequential"
                ))
        
        return results
    
    def _update_global_stats(self, results: List[OptimizationResult], total_time_ms: float):
        """Actualizar estad√≠sticas globales de performance"""
        self.stats["total_optimizations"] += len(results)
        
        # Calcular success rate
        successful = sum(1 for r in results if r.success)
        current_success_rate = successful / len(results) if results else 0.0
        
        # Actualizar promedios
        total_optimizations = self.stats["total_optimizations"]
        if total_optimizations > 0:
            # Success rate promedio ponderado
            prev_weight = (total_optimizations - len(results)) / total_optimizations
            new_weight = len(results) / total_optimizations
            
            self.stats["success_rate"] = (
                self.stats["success_rate"] * prev_weight + 
                current_success_rate * new_weight
            )
            
            # Tiempo de ejecuci√≥n promedio
            self.stats["total_execution_time_ms"] += total_time_ms
            self.stats["avg_execution_time_ms"] = (
                self.stats["total_execution_time_ms"] / total_optimizations
            )
        
        # Actualizar estad√≠sticas por worker
        for result in results:
            self._update_worker_stats(result)
    
    def _update_worker_stats(self, result: OptimizationResult):
        """Actualizar estad√≠sticas espec√≠ficas de worker"""
        worker_id = result.worker_id
        
        if worker_id not in self.worker_stats:
            self.worker_stats[worker_id] = {
                "optimizations_completed": 0,
                "avg_execution_time_ms": 0.0,
                "success_rate": 1.0,
                "last_optimization": None
            }
        
        stats = self.worker_stats[worker_id]
        stats["optimizations_completed"] += 1
        stats["last_optimization"] = datetime.now()
        
        # Actualizar tiempo promedio
        prev_avg = stats["avg_execution_time_ms"]
        completed = stats["optimizations_completed"]
        stats["avg_execution_time_ms"] = (
            (prev_avg * (completed - 1) + result.execution_time_ms) / completed
        )
        
        # Actualizar success rate
        if result.success:
            stats["success_rate"] = (
                (stats["success_rate"] * (completed - 1) + 1.0) / completed
            )
        else:
            stats["success_rate"] = (
                (stats["success_rate"] * (completed - 1) + 0.0) / completed
            )
            
            # Actualizar health del worker
            if worker_id in self.worker_health:
                health = self.worker_health[worker_id]
                health["failures"] += 1
                health["last_failure"] = datetime.now()
                
                # Marcar como unhealthy si muchos fallos
                if health["failures"] > 3:
                    health["healthy"] = False
                    logger.warning(f"üö® Worker {worker_id} marked as unhealthy - {health['failures']} failures")
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """Obtener estad√≠sticas detalladas de performance"""
        # Calcular utilizaci√≥n de workers
        active_workers = sum(
            1 for worker_id, health in self.worker_health.items()
            if health["healthy"]
        )
        worker_utilization = active_workers / self.max_workers if self.max_workers > 0 else 0.0
        
        return {
            "global_stats": {
                "total_optimizations": self.stats["total_optimizations"],
                "parallel_optimizations": self.stats["parallel_optimizations"],
                "sequential_optimizations": self.stats["sequential_optimizations"],
                "avg_execution_time_ms": round(self.stats["avg_execution_time_ms"], 1),
                "success_rate": round(self.stats["success_rate"], 3),
                "parallel_enabled": settings.ORTOOLS_ENABLE_PARALLEL_OPTIMIZATION
            },
            "worker_stats": {
                "max_workers": self.max_workers,
                "active_workers": active_workers,
                "worker_utilization": round(worker_utilization, 3),
                "workers_detail": self.worker_stats,
                "worker_health": self.worker_health
            },
            "performance_analysis": {
                "parallel_efficiency": self._calculate_parallel_efficiency(),
                "bottlenecks": self._identify_bottlenecks(),
                "recommendations": self._generate_recommendations()
            }
        }
    
    def _calculate_parallel_efficiency(self) -> float:
        """Calcular eficiencia de paralelizaci√≥n"""
        if self.stats["parallel_optimizations"] == 0:
            return 0.0
        
        # Theoretical speedup vs actual performance
        # Simplificado: assumir que paralelizaci√≥n deber√≠a ser ~2x m√°s r√°pida
        expected_speedup = min(2.0, self.max_workers * 0.7)  # 70% efficiency expected
        
        # Compare execution times (esto requerir√≠a m√©tricas m√°s detalladas)
        # Por ahora, usar success rate como proxy
        efficiency = self.stats["success_rate"] * expected_speedup / 2.0
        
        return min(1.0, efficiency)
    
    def _identify_bottlenecks(self) -> List[str]:
        """Identificar posibles bottlenecks de performance"""
        bottlenecks = []
        
        if self.stats["avg_execution_time_ms"] > 5000:  # > 5s
            bottlenecks.append("high_avg_execution_time")
        
        if self.stats["success_rate"] < 0.9:
            bottlenecks.append("low_success_rate")
        
        unhealthy_workers = sum(
            1 for health in self.worker_health.values()
            if not health["healthy"]
        )
        if unhealthy_workers > 0:
            bottlenecks.append(f"unhealthy_workers_{unhealthy_workers}")
        
        if not settings.ORTOOLS_ENABLE_PARALLEL_OPTIMIZATION:
            bottlenecks.append("parallel_optimization_disabled")
        
        return bottlenecks
    
    def _generate_recommendations(self) -> List[str]:
        """Generar recomendaciones de optimizaci√≥n"""
        recommendations = []
        
        if self.stats["avg_execution_time_ms"] > settings.ORTOOLS_EXPECTED_EXEC_TIME_MS * 2:
            recommendations.append("Consider reducing problem complexity or increasing timeout")
        
        if self.stats["parallel_optimizations"] < self.stats["sequential_optimizations"]:
            recommendations.append("Enable parallel optimization for better performance")
        
        if self.max_workers < mp.cpu_count():
            recommendations.append(f"Consider increasing max_workers from {self.max_workers} to {mp.cpu_count()}")
        
        return recommendations
    
    async def shutdown(self):
        """Limpiar recursos al cerrar"""
        if self.executor:
            self.executor.shutdown(wait=True)
            logger.info("üîÑ OR-Tools parallel optimizer shutdown completed")

# Singleton instance
ortools_parallel_optimizer = ORToolsParallelOptimizer()

# Export functions para f√°cil uso
async def optimize_parallel_batch(requests: List[Dict[str, Any]]) -> List[OptimizationResult]:
    """
    Optimizar batch de requests en paralelo
    
    Args:
        requests: Lista de requests con places y preferences
        
    Returns:
        Lista de resultados de optimizaci√≥n
    """
    tasks = []
    for i, request in enumerate(requests):
        task = OptimizationTask(
            task_id=f"batch_{i}_{int(time.time())}",
            places=request.get("places", []),
            preferences=request.get("preferences", {}),
            priority=request.get("priority", 1)
        )
        tasks.append(task)
    
    return await ortools_parallel_optimizer.optimize_parallel(tasks)

def get_parallel_optimizer_stats() -> Dict[str, Any]:
    """Obtener estad√≠sticas del optimizador paralelo"""
    return ortools_parallel_optimizer.get_performance_stats()

async def shutdown_parallel_optimizer():
    """Shutdown limpio del optimizador paralelo"""
    await ortools_parallel_optimizer.shutdown()